{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Basics\" K-Means\n",
    "Um die Daten in Cluster aufzuteilen, kann beispielsweise der [K-Means-Algorithmus](https://de.wikipedia.org/wiki/K-Means-Algorithmus) verwendet werden. Eine Implementation davon befindet sich in der Open-Source-Bibliothek [sklearn](https://scikit-learn.org), s.a. [hier](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). Angenommen, wir haben einen Datensatz mit $x_1,\\dots,x_n \\in \\mathbb{R}^r$ Beispielen gegeben. K-Means findet dann $k$ \"gute\" Zentroiden $c_1,\\dots,c_k \\in \\mathbb{R}^r$ ($k$ wird vorher spezifiziert) und determiniert die Clusterzugehörigkeit über die Distanz eines Datenpunkts zu den Zentroiden. Für einen Datenpunkt $x$ wird das passende Cluster also über $$ \\text{cluster}(x) = \\mathrm{argmin}_{\\ell \\in \\{1,\\dots,k\\}} || c_\\ell - x ||^2 $$ berechnet. Wenn ein Autoencoder mit der Kodierungsfunktion $f : \\mathbb{R}^r \\rightarrow \\mathbb{R}^s$ und $s << r$ gegeben ist, kann als Featurevektor statt der Waveforms die Kodierung in den K-Means-Algorithmus gegeben werden. Die Idee ist hier, dass durch die Kodierung einerseits unrepräsentative Features entfernt werden, andererseits aber auch die Dimension die Eingabedaten deutlich verkleinert wird, was dem K-Means-Algorithmus zugute kommt.\n",
    "\n",
    "## Importieren der Bibliotheken und Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepwaveform as dwf\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = dwf.load_dataset(\"../data/mit_uferuebergang.txt\", wv_cols=list(range(64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotieren des Datensatzes mit den Kodierungen eines Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dwf.AutoEncoder(dimensions=12)\n",
    "model.load_state_dict(torch.load(\"trained_models/autoencoder.pt\"))\n",
    "model.eval()\n",
    "model.process_dataframe(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering mit Hilfe von K-Means auf den Waveforms und Autoencoder-Kodierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_waveforms = dwf.waveform2matrix(df, wv_cols=list(range(64)))\n",
    "mat_hidden = dwf.waveform2matrix(df, wv_cols=[\"hidden_\"+str(idx) for idx in range(12)])\n",
    "\n",
    "kmeans = KMeans(n_clusters=5).fit(mat_waveforms)\n",
    "centroids_waveforms = kmeans.cluster_centers_\n",
    "df[\"cluster_waveforms\"] = kmeans.labels_\n",
    "\n",
    "kmeans = KMeans(n_clusters=5).fit(mat_hidden)\n",
    "centroids_hidden = kmeans.cluster_centers_\n",
    "df[\"cluster_hidden\"] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich der gefundenen Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "fig = plt.figure(figsize=(35,9))\n",
    "ax1 = fig.add_subplot(111, projection=\"3d\", title=\"Clustering über komplette Waveforms\")\n",
    "ax2 = fig.add_subplot(122, projection=\"3d\", title=\"Clustering über kodierte Waveforms\")\n",
    "dwf.plot_pcl(df, ax1, targetcol=\"cluster_waveforms\", colormap=cm.Accent)\n",
    "dwf.plot_pcl(df, ax2, targetcol=\"cluster_hidden\", colormap=cm.Accent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zentroiden der Waveforms und Autoencoder-Kodierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,6))\n",
    "\n",
    "xs = np.arange(centroids_waveforms.shape[1])\n",
    "for centroid_idx in range(centroids_waveforms.shape[0]):\n",
    "    ax1.plot(xs, centroids_waveforms[centroid_idx, :], label=\"cluster %d\" % (centroid_idx+1))\n",
    "ax1.set_title(\"Zentroiden der Waveforms\")\n",
    "ax1.set_xlabel(\"Dimension der Zentroiden\")\n",
    "ax1.set_ylabel(\"Amplitude\")\n",
    "ax1.legend()\n",
    "\n",
    "clustercount=centroids_hidden.shape[0]\n",
    "xs = np.arange(centroids_hidden.shape[1])\n",
    "for centroid_idx in range(clustercount):\n",
    "    ax2.plot(xs, centroids_hidden[centroid_idx, :], \"--x\", label=\"cluster %d\" % (centroid_idx+1))\n",
    "ax2.set_title(\"Zentroiden der Kodierungen\")\n",
    "ax2.set_xlabel(\"Dimension der Zentroiden\")\n",
    "ax2.set_ylabel(\"Amplitude\")\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit019ac1ddd4de423abf9b086ca7e6df0b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
