#!/usr/bin/env python3

import argparse
import deepwaveform as dwf
import torch

def train(args):
    print("loading dataset...")
    df = dwf.load_dataset(args.target)
    model, trainerfunc = None, None

    if args.type == "classifier":
        classcount = max(df[args.classcol])+1
        model = dwf.ConvNet(output_dimension=classcount)
        ds = dwf.WaveFormDataset(df, classcol=args.classcol)
        trainer = dwf.Trainer(model,
                              ds, optimizer=None,
                              batch_size=args.batch_size,
                              epochs=args.epochs)
        trainerfunc = trainer.train_classifier
    if args.type == "autoencoder":
        model = dwf.AutoEncoder(hidden=args.hiddendim)
        ds = dwf.WaveFormDataset(df, classcol=None)
        trainer = dwf.Trainer(model,
                              ds, optimizer=None,
                              batch_size=args.batch_size,
                              epochs=args.epochs)
        trainerfunc = trainer.train_autoencoder

    print("initializing training process...")
    for epoch, result in enumerate(trainerfunc(), start=1):
        print("\tepoch=%s p=%.3f loss=%.4f" % (
            str(epoch).zfill(3),
            epoch/args.epochs,
            result["meanloss"]))
    print("storing model...")
    torch.save(model, args.output)


def annotate(args):
    print("loading dataset...")
    df = dwf.load_dataset(args.target)
    if args.output is None:
        args.output = args.target[:-4] + ".annotated.csv"
    print("loading model...")
    model = torch.load(args.model)
    model.eval()
    print("annotating & storing dataframe...")
    if isinstance(model, dwf.ConvNet):
        model.annotate_dataframe(df, class_label_mapping=eval(args.labels))
    else:
        model.annotate_dataframe(df)
    df.to_csv(args.output, sep=";")


def cluster(args):
    print("loading dataset...")
    df = dwf.load_dataset(args.target)
    if args.output is None:
        args.output = args.target[:-4] + ".clustered.csv"
    from sklearn.cluster import KMeans
    print("calculating clusters...")
    mat = dwf.waveform2matrix(df, wv_cols=eval(args.features))
    kmeans = KMeans(n_clusters=args.clustercount).fit(mat)
    df["cluster"] = kmeans.labels_
    print("annotating & storing dataframe...")
    df.to_csv(args.output, sep=";")


def renderclass(args):
    print("loading dataset...")
    df = dwf.load_dataset(args.target)
    import matplotlib.pyplot as plt
    dwf.plot_pcl(df, None, 
                 targetcol=args.classcol,
                 class_label_mapping=eval(args.labels),
                 colors=eval(args.colors),
                 use_plotly=True)


def renderprob(args):
    print("loading dataset...")
    df = dwf.load_dataset(args.target)
    import matplotlib.pyplot as plt
    dwf.plot_pcl_prediction(df, None, 
                 probabilities_col=eval(args.probcols),
                 colors=eval(args.colors),
                 use_plotly=True)


parser = argparse.ArgumentParser(
    formatter_class=argparse.RawDescriptionHelpFormatter)

subparsers = parser.add_subparsers(
    description="Tool for training classifiers and autoencoders on full-length waveform-datasets, annotating datasets with estimated classes/encodings, clustering datasets and visualizing results.")
parser_train = subparsers.add_parser("train", description="Trains a network on a dataset.")
parser_annotate = subparsers.add_parser("annotate",
    description="Annotates a dataset with predicted classes/encodings.")
parser_cluster = subparsers.add_parser("cluster",
    description="Clusters a dataset into multiple partitions. Adds a new 'cluster'-column that contains the predicted cluster index for each element.")
parser_renderclass = subparsers.add_parser("renderclass",
    description="Renders the elements of a dataset as a point cloud dependent on their corresponding class.")
parser_renderprob = subparsers.add_parser("renderprob",
    description="Given a dataset annotated by a classifier with probability estimates for each class, renders the elements of this dataset as a point cloud dependent on their corresponding probability estimates.")

parser_train.add_argument("type", choices=["classifier", "autoencoder"],
    help="The model type that should be trained.")
parser_train.add_argument("target", help="The dataset (.csv-format).")
parser_train.add_argument("--output", "-o", default="model.pt",
    help="Where to store the model.")
parser_train.add_argument("--epochs", "-e", default=20, type=int,
    help="Number of epochs the model should be trained.")
parser_train.add_argument("--batch_size", "-bs", default=128, type=int,
    help="Batch size per epoch.")
parser_train.add_argument("--classcol", "-c", default="class",
    help="[Classifier only] Column in dataset that stores the class.")
parser_train.add_argument("--hiddendim", "-hd", default=12, type=int,
    help="[Autoencoder only] Size of hidden dimension.")
parser_train.set_defaults(func=train)

parser_annotate.add_argument("target", help="The dataset (.csv-format).")
parser_annotate.add_argument("model", help="The model used to annotate the dataset.")
parser_annotate.add_argument("--output", "-o", default=None, 
    help="Where to store the annotated dataset.")
parser_annotate.add_argument("--labels", "-l", default="None", 
    help="[Classifier only] Python code that returns a list which contains labels for each class.")
parser_annotate.set_defaults(func=annotate)

parser_cluster.add_argument("target", help="The dataset (.csv-format).")
parser_cluster.add_argument("--features", "-f", default="list(map(str, range(64)))", 
    help="Python code that returns a list which contains the column names of the features that should be used. Default is '%(default)s', which corresponds to the standard waveform columns.")
parser_cluster.add_argument("--output", "-o", default=None, 
    help="Where to store the clustered dataset.")
parser_cluster.add_argument("--clustercount", "-cc", default=8, type=int,
    help="Number of clusters.")
parser_cluster.set_defaults(func=cluster)

parser_renderclass.add_argument("target", help="The dataset (.csv-format).")
parser_renderclass.add_argument("--classcol", "-c", default="class",
    help="Column in dataset that indicates the class.")
parser_renderclass.add_argument("--labels", "-l", default="None",
    help="Python code that returns a list of labels for each class.")
parser_renderclass.add_argument("--colors", "-co", default="None",
    help="Python code that returns a list of colors for each class.")
parser_renderclass.set_defaults(func=renderclass)

parser_renderprob.add_argument("target", help="The dataset (.csv-format).")
parser_renderprob.add_argument("--probcols", "-pc", default="None", 
    help="Python code that returns a list of columns that contain the probability estimates for each class.")
parser_renderprob.add_argument("--colors", "-co", default="None",
    help="Python code that returns a list of colors for each class.")
parser_renderprob.set_defaults(func=renderprob)

args = parser.parse_args()
args.func(args)
